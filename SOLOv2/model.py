# coding: utf-8

import tensorflow as tf
from tensorflow.keras.regularizers import l2

import numpy as np
import os
from functools import partial

from . import utils
from .backbone import build_backbone
from .layers import convblock, pad_with_coord, points_nms
from .loss import compute_image_loss
from .metrics import BinaryRecall, BinaryPrecision

import tensorflow.keras.layers as layers

CONV_INIT = "he_normal"

NORM_DICT = {"bn": layers.BatchNormalization, "gn": layers.GroupNormalization, "ln": layers.LayerNormalization}


def SOLOv2_head(
    ncls,
    filters_in,
    conv_filters=256,
    kernel_filters=256,
    head_layers=4,
    activation="gelu",
    name="SOLO_head",
    normalization="gn",
    normalization_kw={"groups": 32},
    block_params=None,
    **kwargs
):
    # class and kernel shared heads

    NORM = NORM_DICT.get(normalization.lower(), NORM_DICT["gn"])
    NORM = partial(NORM, **normalization_kw)

    if name is None:
        name = "SOLO_head"

    input_tensor = tf.keras.Input(shape=(None, None, filters_in), name=name + "_input")

    # ct_head = input_tensor
    # No preactivation if groupnorm, because depth of input feature map with coord is not a power of 2
    if block_params is None:
        block_params = {
            "preact": False,
            "groups": 1,
            "activation": activation,
            "normalization": normalization,
            "normalization_kw": normalization_kw,
        }

    class_head = input_tensor[..., :-2]  # no need for coordinates in class head
    kernel_head = input_tensor

    for i in range(head_layers):
        if i == 0:
            conv_filters_in = filters_in - 2
        else:
            conv_filters_in = conv_filters

        class_head = convblock(
            filters_in=conv_filters_in,
            filters_out=conv_filters,
            kernel_initializer=CONV_INIT,
            name=name + "_class_{}_".format(i + 1),
            **block_params
        )(class_head)

    class_head = NORM(name=name + "_class_final_norm")(class_head)
    class_head = layers.Activation(activation, name=name + "_class_final_act")(class_head)

    class_head = layers.Conv2D(
        filters=ncls,
        kernel_size=3,
        strides=1,
        padding="same",
        name=name + "_class_logits",
        kernel_initializer=CONV_INIT,
    )(class_head)

    for i in range(head_layers):
        if i == 0:
            conv_filters_in = filters_in
        else:
            conv_filters_in = conv_filters

        kernel_head = convblock(
            filters_in=conv_filters_in,
            filters_out=conv_filters,
            name=name + "_kernel_{}_".format(i + 1),
            **block_params
        )(kernel_head)

    kernel_head = NORM(name=name + "_kernel_final_norm")(kernel_head)
    kernel_head = layers.Activation(activation, name=name + "_kernel_final_act")(kernel_head)
    kernel_head = layers.Conv2D(
        filters=kernel_filters,
        kernel_size=3,
        strides=1,
        padding="same",
        name=name + "_pred_kernels",
        kernel_initializer=CONV_INIT,
    )(kernel_head)

    return tf.keras.Model(inputs=input_tensor, outputs=[class_head, kernel_head], name=name)


def SOLOv2_mask_head(
    fpn_features,
    in_ch=258,
    mid_ch=128,
    out_ch=256,
    activation="gelu",
    normalization="gn",
    normalization_kw={"groups": 32},
):
    # each FPN level is upscaled to size H/2 x W/2, where H and W are the dims of the input image.
    # TODO: add an option for upscaling only to H/4 x W/4 (like in the original SOLOv2 implementation) to limit memory consumption...
    # Then all levels are added and conv

    outputs = []
    for level, fpn_feature in enumerate(fpn_features):
        if level == len(fpn_features) - 1:
            feature = pad_with_coord(fpn_feature)
            channels = in_ch + 2
        else:
            feature = fpn_feature
            channels = in_ch

        for i in range(level + 1):
            if i > 0:
                feature = layers.UpSampling2D(interpolation="bilinear")(feature)
                channels = mid_ch

            feature = convblock(
                filters_in=channels,
                filters_out=mid_ch,
                activation=activation,
                normalization=normalization,
                normalization_kw=normalization_kw,
                preact=False,
                name="mask_head_P{}{}".format(level + 2, i + 1),
            )(feature)

        outputs.append(feature)

    seg_outputs = layers.Add()(outputs)
    seg_outputs = convblock(
        filters_in=mid_ch,
        filters_out=out_ch,
        kernel_size=1,
        activation=activation,
        normalization=normalization,
        normalization_kw=normalization_kw,
        preact=False,
        name="mask_head_output",
    )(seg_outputs)

    return seg_outputs


def SOLOv2(config):
    """Create the SOLOv2 model using the given config object"""

    if config.load_backbone:
        backbone = tf.keras.models.load_model(config.backbone)
    else:
        backbone = build_backbone(
            config.backbone,
            input_shape=config.imshape,
            classes=config.ncls,
            normalization=config.normalization,
            normalization_kw=config.normalization_kw,
        )

    FPN_inputs = {}
    # use get_output_at(0) instead of .output to avoid Graph disconnected error...
    for lvl, layer in config.connection_layers.items():
        FPN_inputs[lvl] = backbone.get_layer(layer).get_output_at(0)

    fpn_features = FPN(FPN_inputs, pyramid_filters=config.FPN_filters, extra_layers=config.extra_FPN_layers)

    head_model = SOLOv2_head(
        ncls=config.ncls,
        filters_in=config.FPN_filters + 2,
        head_layers=config.head_layers,
        conv_filters=config.head_filters,
        kernel_filters=config.mask_output_filters * config.kernel_size**2,
        activation=config.activation,
        normalization=config.normalization,
        normalization_kw=config.normalization_kw,
    )

    maxdim = max(config.imshape)
    H = config.imshape[0]
    W = config.imshape[1]

    feat_kernel_list, feat_cls_list = [], []
    for level, (feature, grid_size) in enumerate(zip(fpn_features, config.grid_sizes)):
        if level == 0:
            # add maxpool for P2 as in fastetimator implementation https://github.com/fastestimator
            feature = layers.MaxPool2D()(feature)
        feature = pad_with_coord(feature)
        feature = tf.image.resize(feature, size=(grid_size * H // maxdim, grid_size * W // maxdim))
        feat_cls, feat_kernel = head_model(feature)
        feat_kernel_list.append(feat_kernel)
        feat_cls_list.append(feat_cls)

    # to build the mask output, we resize and add all FPN levels, except the extra levels > P5
    mask_output = SOLOv2_mask_head(
        fpn_features[: -config.extra_FPN_layers],
        in_ch=config.FPN_filters,
        mid_ch=config.mask_mid_filters,
        out_ch=config.mask_output_filters,
        activation=config.activation,
        normalization=config.normalization,
        normalization_kw=config.normalization_kw,
    )

    model = tf.keras.Model(
        inputs=backbone.input, outputs=[mask_output, feat_cls_list, feat_kernel_list], name=config.model_name
    )
    return model


def FPN(connection_layers, pyramid_filters=256, name="", extra_layers=0, interpolation="bilinear", weight_decay=0):
    """Feature Pyramid Network using Group Normalization
    connection_layers: dict{"C2":layernameX,"C3":layernameY... to C5} dict of keras layers
    if C2 is not provided, P2 layer is not built.
    activation: activation function default 'relu'
    name: base name of the fpn
    interpolation: type of interpolation when upscaling feature maps (default: "bilinear")
    """

    if name is None:
        name = ""

    try:
        C5 = connection_layers["C5"]
        C4 = connection_layers["C4"]
        C3 = connection_layers["C3"]

    except Exception as e:
        print("Error when building FPN: can't get backbone network connection layers")
        print(e, e.args)

    C2 = connection_layers.get("C2", None)

    outputs = []

    P5 = layers.Conv2D(
        pyramid_filters,
        kernel_size=1,
        padding="same",
        use_bias=True,
        strides=1,
        kernel_initializer=CONV_INIT,
        kernel_regularizer=l2(weight_decay),
        name=name + "FPN_C5P5_",
    )(C5)

    P5up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P5upsampled")(P5)

    C4P4 = layers.Conv2D(
        pyramid_filters,
        kernel_size=1,
        padding="same",
        use_bias=True,
        strides=1,
        kernel_initializer=CONV_INIT,
        kernel_regularizer=l2(weight_decay),
        name=name + "FPN_C4P4_",
    )(C4)

    P4 = layers.Add(name=name + "FPN_P4add")([P5up, C4P4])

    P4up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P4upsampled")(P4)

    C3P3 = layers.Conv2D(
        pyramid_filters,
        kernel_size=1,
        padding="same",
        use_bias=True,
        strides=1,
        kernel_initializer=CONV_INIT,
        kernel_regularizer=l2(weight_decay),
        name=name + "FPN_C3P3_",
    )(C3)
    P3 = layers.Add(name=name + "FPN_P3add")([P4up, C3P3])

    if C2 is not None:
        P3up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P3upsampled")(P3)
        P3up = layers.Conv2D(
            pyramid_filters,
            kernel_size=1,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_P3upconv_",
        )(P3up)
        C2P2 = layers.Conv2D(
            pyramid_filters,
            kernel_size=1,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_C2P2_",
        )(C2)
        P2 = layers.Add(name=name + "FPN_P2add")([P3up, C2P2])

        outputs.append(
            layers.Conv2D(
                pyramid_filters,
                kernel_size=3,
                padding="same",
                use_bias=True,
                strides=1,
                kernel_initializer=CONV_INIT,
                kernel_regularizer=l2(weight_decay),
                name=name + "FPN_P2_",
            )(P2)
        )

    outputs.append(
        layers.Conv2D(
            pyramid_filters,
            kernel_size=3,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_P3_",
        )(P3)
    )

    outputs.append(
        layers.Conv2D(
            pyramid_filters,
            kernel_size=3,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_P4_",
        )(P4)
    )

    outputs.append(
        layers.Conv2D(
            pyramid_filters,
            kernel_size=3,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_P5_",
        )(P5)
    )

    for i in range(extra_layers):
        x = layers.Conv2D(
            pyramid_filters,
            kernel_size=3,
            padding="same",
            use_bias=True,
            strides=1,
            kernel_initializer=CONV_INIT,
            kernel_regularizer=l2(weight_decay),
            name=name + "FPN_P{}_".format(i + 6),
        )(outputs[-1])
        outputs.append(x)

    return outputs


def FPNv2(
    connection_layers,
    pyramid_filters=256,
    activation="gelu",
    name="",
    extra_layers=0,
    interpolation="bilinear",
    normalization="gn",
    normalization_kw={"groups": 32},
):
    """Feature Pyramid Network using Group Normalization
    connection_layers: dict{"C2":layernameX,"C3":layernameY... to C5} dict of keras layers
    if C2 is not provided, P2 layer is not built.
    activation: activation function default 'relu'
    name: base name of the fpn
    interpolation: type of interpolation when upscaling feature maps (default: "bilinear")
    A difference with classic FPN is that we add activation and normalization layer
    """

    if name is None:
        name = ""

    try:
        C5 = connection_layers["C5"]
        C4 = connection_layers["C4"]
        C3 = connection_layers["C3"]

    except Exception as e:
        print("Error when building FPN: can't get backbone network connection layers")
        print(e, e.args)
        raise

    input_shapes = [C5.shape[-1], C4.shape[-1], C3.shape[-1]]
    C2 = connection_layers.get("C2", None)
    if C2 is not None:
        input_shapes.append(C2.shape[-1])
    outputs = []

    # tf.print(input_shapes)

    # We must first add Normalization + activation for models using preactivation

    P5 = convblock(
        filters_in=input_shapes[0],
        filters_out=pyramid_filters,
        kernel_size=(1, 1),
        preact=False,
        activation=activation,
        name=name + "FPN_C5P5_",
        normalization=normalization,
        normalization_kw=normalization_kw,
    )(C5)

    P5up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P5upsampled")(P5)

    C4P4 = convblock(
        filters_in=input_shapes[1],
        filters_out=pyramid_filters,
        kernel_size=(1, 1),
        preact=False,
        activation=activation,
        name=name + "FPN_C4P4_",
        normalization=normalization,
        normalization_kw=normalization_kw,
    )(C4)

    P4 = layers.Add(name=name + "FPN_P4add")([P5up, C4P4])

    P4up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P4upsampled")(P4)
    C3P3 = convblock(
        filters_in=input_shapes[2],
        filters_out=pyramid_filters,
        kernel_size=(1, 1),
        preact=False,
        activation=activation,
        name=name + "FPN_C3P3_",
        normalization=normalization,
        normalization_kw=normalization_kw,
    )(C3)
    P3 = layers.Add(name=name + "FPN_P3add")([P4up, C3P3])

    if C2 is not None:
        P3up = layers.UpSampling2D(size=(2, 2), interpolation=interpolation, name=name + "FPN_P3upsampled")(P3)
        P3up = convblock(
            filters_in=pyramid_filters,
            filters_out=pyramid_filters,
            kernel_size=(3, 3),
            preact=False,
            activation=activation,
            name=name + "FPN_P3upconv_",
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(P3up)
        C2P2 = convblock(
            filters_in=input_shapes[3],
            filters_out=pyramid_filters,
            kernel_size=1,
            preact=False,
            activation=activation,
            name=name + "FPN_C2P2_",
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(C2)
        P2 = layers.Add(name=name + "FPN_P2add")([P3up, C2P2])

        outputs.append(
            convblock(
                filters_in=pyramid_filters,
                filters_out=pyramid_filters,
                kernel_size=3,
                preact=False,
                activation=activation,
                name=name + "FPN_P2_",
                normalization=normalization,
                normalization_kw=normalization_kw,
                attention_kernel=7,
            )(P2)
        )

    outputs.append(
        convblock(
            filters_in=pyramid_filters,
            filters_out=pyramid_filters,
            kernel_size=3,
            preact=False,
            activation=activation,
            name=name + "FPN_P3_",
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(P3)
    )

    outputs.append(
        convblock(
            filters_in=pyramid_filters,
            filters_out=pyramid_filters,
            kernel_size=3,
            preact=False,
            activation=activation,
            name=name + "FPN_P4_",
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(P4)
    )

    outputs.append(
        convblock(
            filters_in=pyramid_filters,
            filters_out=pyramid_filters,
            kernel_size=3,
            preact=False,
            activation=activation,
            name=name + "FPN_P5_",
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(P5)
    )

    for i in range(extra_layers):
        x = convblock(
            filters_in=pyramid_filters,
            filters_out=pyramid_filters,
            kernel_size=3,
            preact=False,
            activation=activation,
            strides=2,
            name=name + "FPN_P{}_".format(i + 6),
            normalization=normalization,
            normalization_kw=normalization_kw,
        )(outputs[-1])
        outputs.append(x)

    return outputs


@tf.function()
def flatten_predictions(predictions, ncls=1, kernel_depth=256):
    """Flatten and concat solo head predictions for each FPN level
    predictions: [pred_cls_list, pred_kernel_list] each list contains predictions by level
    TODO: add strides tensor as output to filter binary masks by size
    """

    num_lvl = len(predictions[0])

    flat_pred_cls = [[]] * num_lvl
    flat_pred_kernel = [[]] * num_lvl

    # Extract and flatten the i-th predicted tensors
    for lvl in range(num_lvl):
        x, y = tf.shape(predictions[0][lvl])[0], tf.shape(predictions[0][lvl])[1]
        # tf.print(tf.shape(predictions[0][lvl]), x*y)
        flat_pred_cls[lvl] = tf.reshape(predictions[0][lvl], [x * y, ncls])
        flat_pred_kernel[lvl] = tf.reshape(predictions[1][lvl], [x * y, kernel_depth])

    # Concat predictions -> one big vector for all scales
    flat_pred_cls = tf.concat(flat_pred_cls, 0)
    flat_pred_kernel = tf.concat(flat_pred_kernel, 0)

    return flat_pred_cls, flat_pred_kernel


@tf.function
def compute_one_image_masks(
    inputs, cls_threshold=0.5, mask_threshold=0.5, nms_threshold=0.5, kernel_size=1, kernel_depth=256, max_inst=400
):
    """given predicted class results and predicted kernels, compute the output one encoded mask tensor
    How to implement mask size filtering by strides whereas all inputs are flattened?
    """

    flat_pred_cls = inputs[0]
    flat_pred_kernel = inputs[1]
    masks_head_output = inputs[2]

    # Only one prediction by pixel
    cls_labels = tf.argmax(flat_pred_cls, axis=-1)
    flat_pred_cls = tf.reduce_max(flat_pred_cls, axis=-1)
    # cls_preds = tf.sigmoid(flat_pred_cls)
    positive_idx = tf.where(flat_pred_cls >= cls_threshold)

    cls_scores = tf.gather_nd(flat_pred_cls, positive_idx)
    cls_labels = tf.gather_nd(cls_labels, positive_idx)

    kernel_preds = tf.gather(flat_pred_kernel, positive_idx[:, 0])  # shape [N, kernel_depth*kernel_size**2]
    kernel_preds = tf.transpose(kernel_preds)  # [kernel_depth*kernel_size**2, N]
    kernel_preds = tf.reshape(
        kernel_preds, (kernel_size, kernel_size, kernel_depth, -1)
    )  # SHAPE [ks, ks, cin, cout] where cin=kernel_depth, cout=N isntances

    seg_preds = tf.sigmoid(tf.nn.conv2d(masks_head_output[tf.newaxis, ...], kernel_preds, strides=1, padding="SAME"))[
        0
    ]  # results is shape [H, W, ninstances]
    seg_preds = tf.transpose(seg_preds, perm=[2, 0, 1])  # reshape to [ninstances, H, W]
    binary_masks = tf.where(seg_preds >= mask_threshold, 1.0, 0.0)  # [N, H, W]

    mask_sum = tf.reduce_sum(binary_masks, axis=[1, 2])  # area of each instance (one instance per slice) -> [N]

    # scale the category score by mask confidence
    mask_scores = tf.math.divide_no_nan(tf.reduce_sum(seg_preds * binary_masks, axis=[1, 2]), mask_sum)  # [N]

    scores = cls_scores * mask_scores  # [N]

    seg_preds, scores, cls_labels = matrix_nms(
        cls_labels, scores, seg_preds, binary_masks, mask_sum, post_nms_k=max_inst, score_threshold=nms_threshold
    )
    # seg_preds = tf.RaggedTensor.from_tensor(tf.reshape(seg_preds,[-1,tf.shape(seg_preds)[1]*tf.shape(seg_preds)[2]]))
    seg_preds = tf.RaggedTensor.from_tensor(seg_preds)
    # scores = tf.RaggedTensor.from_tensor(scores)
    # cls_labels = tf.RaggedTensor.from_tensor(cls_labels)

    return seg_preds, scores, cls_labels


@tf.function
def matrix_nms(
    cls_labels,
    scores,
    seg_preds,
    binary_masks,
    mask_sum,
    sigma=0.5,
    pre_nms_k=800,
    post_nms_k=300,
    score_threshold=0.5,
):
    # Select only first pre_nms_k instances (sorted by scores)
    num_selected = tf.minimum(pre_nms_k, tf.shape(scores)[0])
    indices = tf.argsort(scores, direction="DESCENDING")[:num_selected]
    # keep the selected masks, scores and labels (and mask areas)
    seg_preds = tf.gather(seg_preds, indices)
    seg_masks = tf.gather(binary_masks, indices)
    cls_labels, scores = tf.gather(cls_labels, indices), tf.gather(scores, indices)
    mask_sum = tf.gather(mask_sum, indices)  # [N]

    # calculate iou between different masks
    seg_masks = tf.reshape(seg_masks, shape=(num_selected, -1))  # [N, H*W]
    intersection = tf.matmul(seg_masks, seg_masks, transpose_b=True)  # [N, N]
    mask_sum = tf.tile(mask_sum[tf.newaxis, ...], multiples=[num_selected, 1])  # [N,N]
    union = mask_sum + tf.transpose(mask_sum) - intersection
    iou = tf.math.divide_no_nan(intersection, union)
    iou = tf.linalg.band_part(iou, 0, -1) - tf.linalg.band_part(iou, 0, 0)  # equivalent of np.triu(diagonal=1)

    # iou decay and compensation
    labels_match = tf.tile(cls_labels[tf.newaxis, ...], multiples=[num_selected, 1])
    labels_match = tf.where(labels_match == tf.transpose(labels_match), 1.0, 0.0)
    labels_match = tf.linalg.band_part(labels_match, 0, -1) - tf.linalg.band_part(labels_match, 0, 0)

    decay_iou = iou * labels_match  # iou with any object from same class
    compensate_iou = tf.reduce_max(decay_iou, axis=0)
    compensate_iou = tf.tile(compensate_iou[..., tf.newaxis], multiples=[1, num_selected])
    # matrix nms
    inv_sigma = 1.0 / sigma
    decay_coefficient = tf.reduce_min(tf.exp(-inv_sigma * (decay_iou**2 - compensate_iou**2)), axis=0)

    scores = scores * decay_coefficient
    # scores = tf.where(scores >= score_threshold, scores, 0)
    indices = tf.where(scores >= score_threshold)
    scores = tf.gather_nd(scores, indices)
    seg_preds = tf.gather(seg_preds, tf.reshape(indices, [-1]))

    num_selected = tf.minimum(post_nms_k, tf.shape(scores)[0])
    # select the final predictions
    sorted_indices = tf.argsort(scores, direction="DESCENDING")[:num_selected]
    scores = tf.gather(scores, tf.reshape(sorted_indices, [-1]))
    cls_labels = tf.gather(cls_labels, tf.reshape(sorted_indices, [-1]))

    return seg_preds, scores, cls_labels


@tf.function
def compute_masks(
    flat_cls_pred,
    flat_kernel_pred,
    mask_features,
    cls_threshold=0.5,
    mask_threshold=0.5,
    nms_threshold=0.5,
    kernel_depth=256,
    kernel_size=1,
    max_inst=400,
):
    """Compute mask
    inputs:
        list of predicted class features form SOLO head
        list of predicted kernel features  from SOLO head
        feature maps from mask_head
        ...

    """
    prediction_function = partial(
        compute_one_image_masks,
        cls_threshold=cls_threshold,
        mask_threshold=mask_threshold,
        nms_threshold=nms_threshold,
        kernel_size=kernel_size,
        kernel_depth=kernel_depth,
        max_inst=max_inst,
    )

    seg_preds, scores, cls_labels = tf.map_fn(
        prediction_function,
        [flat_cls_pred, flat_kernel_pred, mask_features],
        fn_output_signature=(
            tf.RaggedTensorSpec(shape=(None, None, None), dtype=tf.float32, ragged_rank=1),
            tf.RaggedTensorSpec(shape=(None), dtype=tf.float32, ragged_rank=0),
            tf.RaggedTensorSpec(shape=(None), dtype=tf.int64, ragged_rank=0),
        ),
    )
    # return predicted segmentation masks as [B, N , H, W] ragged tensor
    return seg_preds, scores, cls_labels


class SOLOv2Model(tf.keras.Model):
    def __init__(self, config, **kwargs):
        super(SOLOv2Model, self).__init__(**kwargs)
        self.config = config
        self.model = SOLOv2(config)
        self.kernel_depth = config.mask_output_filters * config.kernel_size**2
        self.ncls = config.ncls
        self.strides = config.strides

        # losses
        self.seg_loss = tf.keras.metrics.Mean(name="seg_loss", dtype=tf.float32)
        self.cls_loss = tf.keras.metrics.Mean(name="cls_loss", dtype=tf.float32)
        self.total_loss = tf.keras.metrics.Mean(name="total_loss", dtype=tf.float32)

        # Metrics
        self.precision = BinaryPrecision(name="precision")
        self.recall = BinaryRecall(name="recall")

    @property
    def metrics(self):
        return [self.precision, self.recall, self.cls_loss, self.seg_loss, self.total_loss]

    def call(self, inputs, training=False, **kwargs):
        default_kwargs = {"score_threshold": 0.5, "seg_threshold": 0.5, "nms_threshold": 0.5, "max_detections": 400}

        default_kwargs.update(kwargs)

        mask_head_output, feat_cls_list, feat_kernel_list = self.model(inputs, training=training)

        # Apply Points NMS in inference
        for lvl in range(len(feat_cls_list)):
            feat_cls_list[lvl] = points_nms(tf.sigmoid(feat_cls_list[lvl]))

        flatten_predictions_func = partial(flatten_predictions, ncls=self.ncls, kernel_depth=self.kernel_depth)
        flat_cls_pred, flat_kernel_pred = tf.map_fn(
            flatten_predictions_func, [feat_cls_list, feat_kernel_list], fn_output_signature=(tf.float32, tf.float32)
        )

        seg_preds, scores, cls_labels = compute_masks(
            flat_cls_pred,
            flat_kernel_pred,
            mask_head_output,
            cls_threshold=default_kwargs["score_threshold"],
            mask_threshold=default_kwargs["seg_threshold"],
            nms_threshold=default_kwargs["nms_threshold"],
            kernel_depth=self.config.mask_output_filters,
            kernel_size=self.config.kernel_size,
            max_inst=default_kwargs["max_detections"],
        )

        return seg_preds, scores, cls_labels

    @tf.function
    def train_step(self, inputs):
        gt_img = inputs[1]
        gt_mask_img = inputs[2]
        gt_boxes = inputs[3]
        gt_cls_ids = inputs[4]
        gt_labels = inputs[5]

        nx = tf.shape(inputs[1])[1]
        ny = tf.shape(inputs[1])[2]

        # Compute flattened targets

        compute_targets_func = partial(
            utils.compute_solo_cls_targets,
            shape=(nx, ny),
            strides=self.strides,
            grid_sizes=self.config.grid_sizes,
            scale_ranges=self.config.scale_ranges,
            offset_factor=self.config.offset_factor,
        )
        class_targets, label_targets = tf.map_fn(
            compute_targets_func,
            (gt_boxes, gt_labels, gt_cls_ids, gt_mask_img),
            fn_output_signature=(tf.int32, tf.int32),
        )

        # OHE class targets and delete bg
        class_targets = tf.one_hot(class_targets, self.ncls + 1)[..., 1:]

        with tf.GradientTape() as tape:
            mask_head_output, feat_cls_list, feat_kernel_list = self.model(gt_img, training=True)

            flatten_predictions_func = partial(flatten_predictions, ncls=self.ncls, kernel_depth=self.kernel_depth)
            # Flattened tensor over locations and levels [B, locations, ncls] and [B, locations, kern_depth]
            flat_cls_pred, flat_kernel_pred = tf.map_fn(
                flatten_predictions_func,
                [feat_cls_list, feat_kernel_list],
                fn_output_signature=(tf.float32, tf.float32),
            )

            flat_cls_pred = tf.sigmoid(flat_cls_pred)

            loss_function = partial(
                compute_image_loss,
                weights=self.config.lossweights,
                kernel_size=self.config.kernel_size,
                kernel_depth=self.config.mask_output_filters,
            )
            cls_loss, seg_loss = tf.map_fn(
                loss_function,
                [class_targets, label_targets, gt_mask_img, flat_cls_pred, flat_kernel_pred, mask_head_output],
                fn_output_signature=(tf.float32, tf.float32),
            )

            # avg over batch size
            cls_loss = tf.reduce_mean(cls_loss)
            seg_loss = tf.reduce_mean(seg_loss)

            # Update loss
            self.seg_loss.update_state(seg_loss)
            self.cls_loss.update_state(cls_loss)

            total_loss = cls_loss + seg_loss
            self.total_loss.update_state(total_loss)

            grads = tape.gradient(total_loss, self.trainable_variables)

            self.optimizer.apply_gradients(
                (grad, var) for (grad, var) in zip(grads, self.trainable_variables) if grad is not None
            )

        # Update Metrics
        if self.ncls == 1:
            class_targets = class_targets[..., tf.newaxis]
        self.precision.update_state(class_targets, flat_cls_pred)
        self.recall.update_state(class_targets, flat_cls_pred)

        return {m.name: m.result() for m in self.metrics}

    def test_step(self, inputs):
        gt_img = inputs[1]
        gt_mask_img = inputs[2]
        gt_boxes = inputs[3]
        gt_cls_ids = inputs[4]
        gt_labels = inputs[5]

        nx = tf.shape(inputs[1])[1]
        ny = tf.shape(inputs[1])[2]

        # Compute targets
        compute_targets_func = partial(
            utils.compute_solo_cls_targets,
            shape=(nx, ny),
            strides=self.strides,
            grid_sizes=self.config.grid_sizes,
            scale_ranges=self.config.scale_ranges,
            offset_factor=self.config.offset_factor,
        )
        class_targets, label_targets = tf.map_fn(
            compute_targets_func,
            (gt_boxes, gt_labels, gt_cls_ids, gt_mask_img),
            fn_output_signature=(tf.int32, tf.int32),
        )

        # OHE class targets and delete bg
        class_targets = tf.one_hot(class_targets, self.ncls + 1)[..., 1:]

        mask_head_output, feat_cls_list, feat_kernel_list = self.model(gt_img, training=True)

        flatten_predictions_func = partial(flatten_predictions, ncls=self.ncls, kernel_depth=self.kernel_depth)
        # Flattened tensor over locations and levels [B, locations, ncls] and [B, locations, kern_depth]
        flat_cls_pred, flat_kernel_pred = tf.map_fn(
            flatten_predictions_func, [feat_cls_list, feat_kernel_list], fn_output_signature=(tf.float32, tf.float32)
        )

        flat_cls_pred = tf.sigmoid(flat_cls_pred)

        loss_function = partial(
            compute_image_loss,
            weights=self.config.lossweights,
            kernel_size=self.config.kernel_size,
            kernel_depth=self.config.mask_output_filters,
        )
        cls_loss, seg_loss = tf.map_fn(
            loss_function,
            [class_targets, label_targets, gt_mask_img, flat_cls_pred, flat_kernel_pred, mask_head_output],
            fn_output_signature=(tf.float32, tf.float32),
        )

        # avg over batch size
        cls_loss = tf.reduce_mean(cls_loss)
        seg_loss = tf.reduce_mean(seg_loss)

        # Update Metrics
        if self.ncls == 1:
            class_targets = class_targets[..., tf.newaxis]
        self.precision.update_state(class_targets, flat_cls_pred)
        self.recall.update_state(class_targets, flat_cls_pred)

        # Update loss
        self.seg_loss.update_state(seg_loss)
        self.cls_loss.update_state(cls_loss)
        self.total_loss.update_state(cls_loss + seg_loss)

        return {m.name: m.result() for m in self.metrics}


def train(
    model,
    train_dataset,
    epochs,
    batch_size=1,
    val_dataset=None,
    steps_per_epoch=None,
    validation_steps=None,
    optimizer=None,
    callbacks=None,
    initial_epoch=0,
    prefetch=tf.data.AUTOTUNE,
    buffer=None,
):
    # Dataset returns name, image, mask, bboxes, classes, labels

    if buffer is None:
        buffer = len(train_dataset)

    train_dataset = train_dataset.shuffle(buffer, reshuffle_each_iteration=True)
    train_dataset = train_dataset.ragged_batch(batch_size)
    # tf.data.experimental.dense_to_ragged_batch(batch_size))
    train_dataset = train_dataset.repeat(epochs)

    if val_dataset is not None and (validation_steps is None or validation_steps is None > 0):
        val_dataset = val_dataset.ragged_batch(batch_size)
        # tf.data.experimental.dense_to_ragged_batch(batch_size))
        validation_steps = len(val_dataset)
        val_dataset = val_dataset.repeat(epochs)

    if steps_per_epoch is None:
        steps_per_epoch = len(train_dataset)

    print("Length of the batched dataset:", len(train_dataset))
    print("number of epochs:", epochs)
    print("number of training steps per epoch", steps_per_epoch)
    print("number of validation steps per epoch", validation_steps)

    train_dataset = train_dataset.prefetch(prefetch)
    if val_dataset is not None:
        val_dataset = val_dataset.prefetch(prefetch)

    # Here lr can be a scheduler
    if optimizer is not None:
        model.optimizer = optimizer
        model.compile(optimizer=model.optimizer)
    else:
        if model.optimizer is None:
            model.optimizer = tf.keras.optimizers.Adam()
            model.compile(optimizer=model.optimizer)

    print("Training using {} optimizer with lr0={}".format(model.optimizer._name, model.optimizer.lr.numpy()))

    history = model.fit(
        train_dataset,
        steps_per_epoch=steps_per_epoch,
        initial_epoch=initial_epoch,
        epochs=epochs,
        validation_data=val_dataset,
        validation_steps=validation_steps,
        callbacks=callbacks,
    )
    return history


def eval(model, dataset, maxiter, threshold=0.75, **kwargs):
    """compute AP score (for now it does not compute AP per class, but for all classes)
    inputs:
    model: SOLOv2 model
    dataset: tf.dataset (e.g. dataset attribute of the DataLoader class)
    maxiter: number of images used
    threshold: iou threshold

    outputs:
    AP
    sorted scores
    precision
    interpolated precision
    recall

    TODO: add per class AP
    TODO: deal with multiple positive predictions for the same GT object
    """

    from sklearn.metrics import auc

    default_kwargs = {"score_threshold": 0.5, "seg_threshold": 0.5, "nms_threshold": 0.5, "max_detections": 400}

    default_kwargs.update(kwargs)

    for i, data in enumerate(dataset):
        if i >= maxiter:
            break

        imgname = data[0].numpy()[0]
        gt_img = data[1]
        gt_mask_img = data[2]
        gt_boxes = data[3]
        gt_cls_ids = data[4]
        gt_labels = data[5]

        seg_preds, scores, cls_labels = model(gt_img, training=False, **default_kwargs)
        seg_preds = seg_preds[0, ...].to_tensor()
        scores = scores[0, ...]

        labels, _ = tf.unique(tf.reshape(gt_mask_img, [-1]))
        ngt = tf.size(labels) - 1

        gt_masks = tf.one_hot(gt_mask_img, ngt + 1)[..., 1:]
        gt_masks = tf.reshape(gt_masks, [-1, ngt])
        gt_masks = tf.transpose(gt_masks, [1, 0])

        pred_masks = tf.where(seg_preds > default_kwargs["seg_threshold"], 1, 0)
        pred_masks = tf.reshape(pred_masks, shape=(pred_masks.shape[0], -1))  # [Npred, H*W]
        print(
            "Processing image {}/{}: {} containing {} objets. Detected : {}".format(
                i + 1, maxiter, imgname, ngt, pred_masks.shape[0]
            )
        )
        gt_masks = tf.cast(gt_masks, tf.int32)

        intersection = tf.matmul(gt_masks, pred_masks, transpose_b=True)

        gt_sums = tf.reduce_sum(gt_masks, axis=1)
        gt_sums = tf.tile(gt_sums[tf.newaxis, ...], multiples=[pred_masks.shape[0], 1])  # [Npred x NGT]

        pred_sums = tf.reduce_sum(pred_masks, axis=1)
        pred_sums = tf.tile(pred_sums[tf.newaxis, ...], multiples=[ngt, 1])  # [NGT, Npred]

        union = tf.transpose(gt_sums) + pred_sums - intersection
        iou = tf.math.divide_no_nan(tf.cast(intersection, tf.float32), tf.cast(union, tf.float32))

        # iou représente la matrice des ious entre GT et PRED (nGT lignes, npred colonnes)

        inds = tf.argmax(iou, axis=0)  # indices des meilleures iou entre pred et GT

        if i == 0:
            all_iou = tf.reduce_max(iou, axis=0)
            TP = tf.where(all_iou > threshold, True, False)  # storing if a predicted box is TP or FP
            all_scores = tf.gather(scores, inds)  # Get predicted box scores
        else:
            all_iou = tf.concat([all_iou, tf.reduce_max(iou, axis=0)], axis=-1)
            TP = tf.concat([TP, tf.where(all_iou > threshold, True, False)], axis=-1)
            all_scores = tf.concat([all_scores, tf.gather(scores, inds)], axis=-1)

    # Sort by score
    sorted_indices = tf.argsort(all_scores, direction="DESCENDING")
    sorted_TP = tf.gather(TP, sorted_indices)
    sorted_scores = tf.gather(all_scores, sorted_indices)

    npred = sorted_TP.shape[0]

    TP = 0
    FP = 0
    recall = np.zeros(npred, dtype=float)
    precision = np.zeros(npred, dtype=float)

    for i in range(npred):
        if sorted_TP[i]:
            TP += 1
        else:
            FP += 1

        recall[i] = TP / npred
        precision[i] = TP / (TP + FP)

    decreasing_max_precision = np.maximum.accumulate(precision[::-1])[::-1]

    AP = auc(recall, decreasing_max_precision)

    return AP, sorted_scores, precision, decreasing_max_precision, recall
